{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizado Supervisionado\n",
    "## Projeto: Encontrando doadores para a *CharityML*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seja bem-vindo ao segundo projeto do Nanodegree Engenheiro de Machine Learning! Neste notebook, você receberá alguns códigos de exemplo e será seu trabalho implementar as funcionalidades adicionais necessárias para a conclusão do projeto. As seções cujo cabeçalho começa com **'Implementação'** indicam que o bloco de código posterior requer funcionalidades adicionais que você deve desenvolver. Para cada parte do projeto serão fornecidas instruções e as diretrizes da implementação estarão marcadas no bloco de código com uma expressão `'TODO'`. \n",
    "Por favor, leia cuidadosamente as instruções!\n",
    "\n",
    "Além de implementações de código, você terá de responder questões relacionadas ao projeto e à sua implementação. Cada seção onde você responderá uma questão terá um cabeçalho com o termo **'Questão X'**. Leia com atenção as questões e forneça respostas completas nas caixas de texto que começam com o termo **'Resposta:'**. A submissão do seu projeto será avaliada baseada nas suas resostas para cada uma das questões além das implementações que você disponibilizar.\n",
    "\n",
    ">**Nota:** Por favor, especifique QUAL A VERSÃO DO PYTHON utilizada por você para a submissão deste notebook. As células \"Code\" e \"Markdown\" podem ser executadas utilizando o atalho do teclado **Shift + Enter**. Além disso, as células \"Markdown\" podem ser editadas clicando-se duas vezes na célula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando\n",
    "\n",
    "Neste projeto, você utilizará diversos algoritmos de aprendizado supervisionado para modelar com precisão a remuneração de indivíduos utilizando dados coletados no censo americano de 1994. Você escolherá o algoritmo mais adequado através dos resultados preliminares e irá otimizá-lo para modelagem dos dados. O seu objetivo com esta implementação é construir um modelo que pode predizer com precisão se um indivíduo possui uma remuneração superior a $50,000. Este tipo de tarefa pode surgir em organizações sem fins lucrativos que sobrevivem de doações. Entender a remuneração de um indivíduo pode ajudar a organização o montante mais adequado para uma solicitação de doação, ou ainda se eles realmente deveriam entrar em contato com a pessoa. Enquanto pode ser uma tarefa difícil determinar a faixa de renda de uma pesssoa de maneira direta, nós podemos inferir estes valores através de outros recursos disponíveis publicamente. \n",
    "\n",
    "O conjunto de dados para este projeto se origina do [Repositório de Machine Learning UCI](https://archive.ics.uci.edu/ml/datasets/Census+Income) e foi cedido por Ron Kohavi e Barry Becker, após a sua publicação no artigo _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. Você pode encontrar o artigo de Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). Os dados que investigaremos aqui possuem algumas pequenas modificações se comparados com os dados originais, como por exemplo a remoção da funcionalidade `'fnlwgt'` e a remoção de registros inconsistentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Explorando os dados\n",
    "Execute a célula de código abaixo para carregas as bibliotecas Python necessárias e carregas os dados do censo. Perceba que a última coluna deste conjunto de dados, `'income'`, será o rótulo do nosso alvo (se um indivíduo possui remuneração igual ou maior do que $50,000 anualmente). Todas as outras colunas são dados de cada indívduo na base de dados do censo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>India</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age          workclass education_level  education-num  \\\n",
       "0    39          State-gov       Bachelors           13.0   \n",
       "1    50   Self-emp-not-inc       Bachelors           13.0   \n",
       "2    38            Private         HS-grad            9.0   \n",
       "3    53            Private            11th            7.0   \n",
       "4    28            Private       Bachelors           13.0   \n",
       "5    37            Private         Masters           14.0   \n",
       "6    49            Private             9th            5.0   \n",
       "7    52   Self-emp-not-inc         HS-grad            9.0   \n",
       "8    31            Private         Masters           14.0   \n",
       "9    42            Private       Bachelors           13.0   \n",
       "10   37            Private    Some-college           10.0   \n",
       "11   30          State-gov       Bachelors           13.0   \n",
       "12   23            Private       Bachelors           13.0   \n",
       "13   32            Private      Assoc-acdm           12.0   \n",
       "14   34            Private         7th-8th            4.0   \n",
       "\n",
       "            marital-status          occupation    relationship  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   \n",
       "5       Married-civ-spouse     Exec-managerial            Wife   \n",
       "6    Married-spouse-absent       Other-service   Not-in-family   \n",
       "7       Married-civ-spouse     Exec-managerial         Husband   \n",
       "8            Never-married      Prof-specialty   Not-in-family   \n",
       "9       Married-civ-spouse     Exec-managerial         Husband   \n",
       "10      Married-civ-spouse     Exec-managerial         Husband   \n",
       "11      Married-civ-spouse      Prof-specialty         Husband   \n",
       "12           Never-married        Adm-clerical       Own-child   \n",
       "13           Never-married               Sales   Not-in-family   \n",
       "14      Married-civ-spouse    Transport-moving         Husband   \n",
       "\n",
       "                   race      sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                 White     Male        2174.0           0.0            40.0   \n",
       "1                 White     Male           0.0           0.0            13.0   \n",
       "2                 White     Male           0.0           0.0            40.0   \n",
       "3                 Black     Male           0.0           0.0            40.0   \n",
       "4                 Black   Female           0.0           0.0            40.0   \n",
       "5                 White   Female           0.0           0.0            40.0   \n",
       "6                 Black   Female           0.0           0.0            16.0   \n",
       "7                 White     Male           0.0           0.0            45.0   \n",
       "8                 White   Female       14084.0           0.0            50.0   \n",
       "9                 White     Male        5178.0           0.0            40.0   \n",
       "10                Black     Male           0.0           0.0            80.0   \n",
       "11   Asian-Pac-Islander     Male           0.0           0.0            40.0   \n",
       "12                White   Female           0.0           0.0            30.0   \n",
       "13                Black     Male           0.0           0.0            50.0   \n",
       "14   Amer-Indian-Eskimo     Male           0.0           0.0            45.0   \n",
       "\n",
       "    native-country income  \n",
       "0    United-States  <=50K  \n",
       "1    United-States  <=50K  \n",
       "2    United-States  <=50K  \n",
       "3    United-States  <=50K  \n",
       "4             Cuba  <=50K  \n",
       "5    United-States  <=50K  \n",
       "6          Jamaica  <=50K  \n",
       "7    United-States   >50K  \n",
       "8    United-States   >50K  \n",
       "9    United-States   >50K  \n",
       "10   United-States   >50K  \n",
       "11           India   >50K  \n",
       "12   United-States  <=50K  \n",
       "13   United-States  <=50K  \n",
       "14          Mexico  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importe as bibliotecas necessárias para o projeto.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Permite a utilização da função display() para DataFrames.\n",
    "\n",
    "# Importação da biblioteca de visualização visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Exibição amigável para notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Carregando os dados do Censo\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Sucesso - Exibindo o primeiro registro\n",
    "display(data.head(n=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Explorando os Dados\n",
    "\n",
    "Uma investigação superficial da massa de dados determinará quantos indivíduos se enquadram em cada grupo e nos dirá sobre o percentual destes indivúdos com remuneração anual superior à \\$50,000. No código abaixo, você precisará calcular o seguinte:\n",
    "- O número total de registros, `'n_records'`\n",
    "- O número de indivíduos com remuneração anual superior à \\$50,000, `'n_greater_50k'`.\n",
    "- O número de indivíduos com remuneração anual até \\$50,000, `'n_at_most_50k'`.\n",
    "- O percentual de indivíduos com remuneração anual superior à \\$50,000, `'greater_percent'`.\n",
    "\n",
    "** DICA: ** Você pode precisar olhar a tabela acima para entender como os registros da coluna `'income'` estão formatados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Número total de registros.\n",
    "n_records = len(data.index)\n",
    "\n",
    "# TODO: Número de registros com remuneração anual superior à $50,000\n",
    "n_greater_50k = len(data[data.income == '>50K'])\n",
    "\n",
    "# TODO: O número de registros com remuneração anual até $50,000\n",
    "n_at_most_50k = len(data[data.income == '<=50K'])\n",
    "\n",
    "# TODO: O percentual de indivíduos com remuneração anual superior à $50,000\n",
    "greater_percent = (n_greater_50k/(n_records))*100\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Explorando as colunas **\n",
    "* **age**: contínuo. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: contínuo. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: contínuo. \n",
    "* **capital-loss**: contínuo. \n",
    "* **hours-per-week**: contínuo. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparando os dados\n",
    "Antes de que os dados possam ser utilizados como input para algoritmos de machine learning, muitas vezes eles precisam ser tratados, formatados e reestruturados — este processo é conhecido como **pré-processamento**. Felizmente neste conjunto de dados não existem registros inconsistentes para tratamento, porém algumas colunas precisam ser ajustadas. Este pré-processamento pode ajudar muito com o resultado e poder de predição de quase todos os algoritmos de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os principais desvios das colunas contínuas\n",
    "Um conjunto de dados pode conter ao menos uma coluna onde os valores tendem a se próximar para um único número, mas também podem conter registros com o mesmo atributo contendo um valor muito maior ou muito menor do que esta tendência. Algoritmos podem ser sensíveis para estes casos de distribuição de valores e este fator pode prejudicar sua performance se a distribuição não estiver normalizada de maneira adequada. Com o conjunto de dados do censo, dois atributos se encaixam nesta descrição: '`capital-gain'` e `'capital-loss'`.\n",
    "\n",
    "Execute o código da célula abaixo para plotar um histograma destes dois atributos. Repare na distribuição destes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3XmYLFV9//H3h1VERVRABBQlxiXGBRAxGgQXRFyIW4IRubgbNdGoP8UVxF0jCjFuUQSXuKEiIoqIgiuyiYALiwJ6ZRUUWQQEzu+Pc5rbt+mZqbl3eqZn+v16nn6m69TpqlNVPXX6W+fUqZRSkCRJkqQu1ljoAkiSJElaPAwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEFpQSf4pyfeSXJLkL0nOT3JYkl368uyVpCT5m4Us66rqK/+WM+Q7uOUrSW5KckWSXyT5eJKHrupyh3zmObMs/8FJzuub3rKt93mzWc6qlGtVtnGcJFkjyfuTXNiO6WEz5F8/yWuTnJLkyiTXJjkzyQdG+f1Psm+SRw5JX+nYL3VJ7tr29dlt31+V5MQkr0+ywUKXb1T6zjslyV+TXJrk+0nemGTj1Vju0O/VapZ134Hy9r9G8j+yKudNaalba6ELoMmV5D+AA4CDgPcAVwNbAY8HHgl8c+FKt2AuBZ7U3q8P3AvYA/hRkneWUl7bl/frwEOBC2ex/L2o//cHzeIzb6Eep1Hai+HlWpVtHCdPA14GvBL4MXDZVBmTbAp8G7gL8AHgB8D1wH2B5wAPAx40onLuA7wN+M5A+nwc+7GQZAfgcOAS4EDgDGBtYHvgJcCdgP9csAKO3sHAR6gXFu9I3e5/B/4jyW6llB+twjKn+l7NhYcDNw6k/W4E64FVO29KS5oBhBbSq4DDSinP7Uv7DvC/SSa1dez6UsrxfdPHJPkQ8D5g7yQnlVK+BFBKuZQacIxEknVLKdeVUn49qnXMZNTbOA/u0/6+v5Ry0wx5PwVsCmxXSjm7L/27ST4I7DaKAk5nIY/9fEqyIXAo8Evg0aWUq/tmfyvJe4F/WJDCzZ/fD5x7vpbkQOD7wJeTbDWwXxbaT0opNyx0IVZVkrWBG4pP89UiNak/0jQe7gBcNGzGTD+2kmyT5OIkX05yq5a2Vuv+8ask1yW5IMl7e/NbnjOSfKxveoMkNyZZPrD8Hyb5Qt/0jMtu+e6R5OtJrmndAA4A1p3NThmyLwrwauBi4OV967pF954k/5rkp63rxRVJTk/ywjbvWOARwMP6mvyPHVjWDkm+mORPwE/avKm6sayTZP/U7mfXJDlisKtRW+a+A2m9LlB7zaJc/du4dpK3JjkvyfXt71tbhTy4jhcm2S+1C9GfknwtyeYD5Zlyn00nyS5Jfpza9e6K1K539+qbfx7Q2/Yb+7d5yLK2Ax4FvH0geADqd6CUclhf/jnbB0l6P2Be37f/923zpuq+1mW/znjs+9L3SPKz1G5Df0jyqdQWmVkvL8mDkxyd5LL2vfxNagA2necDGwH/PuxHcinl6lLK0X3ruHWSdyU5t+3/c1O7Oa3Rl2fHVrYnpXaL+kPqOeHTSW4/sB0vS/LL9l36Y5KTkjy5b/55SQ4eLNfgPknyt0m+0v4nr03y29T/51W6WFhKuRj4f8AmwO5969k5yZHt+F+Tel59ZZI1+8vW3g77Xj04yaFJlrdtPjPJ25OstyrlHCbJ3ZN8pu3z65Kc2r9PW56/ad+1c1s5fpPkQ6kBZS/PsUx9ftq3bzv7lzvV/82Lk7w7yQXAdcDtZ1HWOT220uryi6eFdAKwLMlvgK+WUs7q8qEkOwNfAj4DvKSU0mvG/jTwROBdwI+oV3/fAmwJPLXl+Q7whL7F7Ug9kW+W5G9LKWclWR94cFtez4zLTrIOcDSwHrXLwyXAC4GndNmu6ZRSrk9yDPC0JGsNu/KW5OGtnAdSK/01gHvTKingxW3+mq1cAH8eWMxngM9Su97MdH54LXAq8GxgY+Dt1Ku1f1dK+essNq9LufodAvxzW98PqF2c3gDcA/jXIWX8EbUL0MbAe6nb+AjotM+GSr1H5+vU79O/ALcB9gN+kOSBpZTfA08G/oPa/aF3D8tUV/Qf3f4ePt16+8zZPmif/TErurAALGd6My2zsyQvaOv9fFvuXdp2PSTJ1qWUq2axrNsAR1HPLXsBV1L/R2dqPXg0cFEp5aQO61irreO+1HPA6dTuPm+kXhR55cBHDgCOoB6XewHvpna9WdaW90zq/tuPerV/PeD+bVmzdQTwJ+DfgD8AmwG7snoXC78F3EDtQvfxlnYP4Bjgv4FrgW2pwfJGwN4tz3Tfq7tSzx0HU4/R3wFvasu9OVCZwZpJ+qdv6l14SrIF9QLIJdRuZ5dS/0+/lOSfSim9/7O7tDK9HPhjW//rgCNZ8T872/PTdF4PnAi8oC3v2lmUdRTHVlp1pRRfvhbkBfwtcBpQ2usP1B+vOw/k26vN/xvgmdR+4fsN5PnHlmfPgfRntvQHtuknt+m7ten3U3+0nQ28sKXt0vLce5bLfn6b3r4vzxrAz1v6ljPsj4OB5dPMf0dbziYD+2XLNv0q4PIZ1nEs8IMh6b1lvW+Kcp3XN71ly/sLYI2+9Ie19Of2pRVg34Hl9T6/1yzK1dvG+02xzDe09PsPrOO4gXyvaul36brPptiPJ7XvzFp9aXcH/grs35f2Vloj0gzL+1Ar17od8s7pPug7Tm+dxbHvusxpjz31R9TFwHcH8j285fuPWS5v2/59MIvj+Uvgxx3zPqutY4eB9NdTz00bt+kdW75DBvJ9gPqjO33Tp8ywzvOAg4ek37xPqPdoFOBJq/B9Hnr8++ZfCHxjinmhXmx4PfVH+Bpdlzvw+T2Am4A7zpB/X1bUGf2vT/fl+Tj1h/gdBz57NHDqNMteq++796C+9GMZfn7alyH/39P835zSO+6zKevqHFtfvkb1MnLVgim1xeFB1KuWb6NekXoycFSSNwz5yMupJ+aXlVLeNDBvF2rl/aXU7kZrtSuF32rzd2h/j6NWUr2RQR5JvYr8nYG0C0spv5rlsh8K/K709SMu9YrYzV2hVlPvcluZYv6JwIati8QTBrtJdPSVWeQ9tPR1NSul/JB6Ne8WI0bNod6+/vRAem968Ar41wemT29/79r+znqftRaqrYHPl76WoFLKucAPh5Rhrs31PlgVc7XMe1FbMD7Tn1hK+QFwPrPfl2dTr9J+JLVb1Baz/HwXu1DL9qMh54PeTdf9hu2rdandgqB+Bx+Y5L+TPDrJrVexXJcBvwHemeT5Se65issZJvSdd5JsmuQjSc6nnhv/Sg2Wb089ntMvLLldahewX1NbgP9KvQcoQNdyb09tKe693tg3bxdqK8IVA8foKOABSW7XyrFOkteldk39SyvH99sy7sXcO6yUMnj+7lLWUR5baZUYQGhBlVJuLKV8r5TyhlLKo6lNyKcD+/T3Q212B35P7b40aGNgHeAqaiXQe13S5t+xre9y4GfATknuRL2a+9322rHl3alNz2rZ1BtgLx5StmFpq2ILamV9+bCZpZTjgKe3fF8BLk3y7ST3n8U6ZjPa0VTbutksljFbvW4dg+W8aGB+z+C+uq79vRWs8j7bkPpDZ9i+umhIGbrojR5ztw5553QfrKK5WuZU2wKrsC9LKVdQ/38vAD4I/Lb1z3/q9J/kd9SrxF1sTD1Ofx14ndDm33Eg/0z76pPUbikPof5ovDz13q6u5QFuvlfqMdTWsXcAZ7U+/f82m+UMavcl3Il2jFLv8zic2hX0rdQLLg+mXgSCbt+BTwAvonYdfEz7/Etm8XmAk0spJ/W9zu2btzGwJ7c8Ru9p83vH6B3UVoRPU0f/244VXU5X5/9jKsO+5zOWdVTHVlod3gOhsVJKuSD1JucDqFeiTuib/VTgo8CxSR5ZSum/AfsyareAf5xi0Rf0vf8utY/pTu1zp1FP7Bsn6Q2V+ZG+/F2XfSG1L++gTYakzUq7v+LRwPFlmpFHSimHAoe2vuA7Uu/Z+GaSzcvMowDB1K0bwwzbrk2oLUk911GDr36DP7Bmo/dj7M6sfD/BndvfKYdJncoq7LM/UvfTnYfMu/OqlIE6fOvbqPfZvHeGvHO+D0aky7Hv35ZBd6b+YJrN8iilnAo8tV3F3ZZ6X8UXkjyglHLGFGX9NvCYJNuUUk6eIk/PZcC51HtQhjlvhs8PlrdQzzcfaRdNdqZ+Bz5PDSqgnn9W2vYktwiuSim/AfZMvTngAcBLgQ8mOa+U8o3ZlKvPY6ldzX7Qprei7tdnlVJubgVL8sQuC0sdeGI3aterA/rS/34VyzfMZdSWhHdNMb93zt4d+GQp5a195bjNLNZzbfvMOqWU6/vSpzrHDTu/dirriI6ttMpsgdCCmaZ7wb3b38ERmn5P/YG3BnVoy/5RWr5JvWK0wcBVqd5rMIDYjHpD3LGluoR6r8KbqZXld1Zh2T8GtkhycxeGdrVuqh8anbQK493UK1Xv6/KZUspVpZQjqD9MNmVFhXYd9SbNufC0rDzqzMOAzan7oed8aitPv8cPWVbXch3X/g7eaPnM9vd7HZYx1DT7bDDf1cDJwNOz8qgzd6PerHvcsM/NsO4TqDelvi5TPAwrSW8Y11Hsg+uZu+9FT5djfya11WqlbUnyD9Sr/P37sut3CYBSyg2tO+EbqeeM+0yVF/gY9R6sD7QuaitJHXWpd6P7N6ktVldNcT74wzTrmVYp5Y+llM9Tuz32b+uwbX8CU2jntFOBV7Skwc92kvoQuXdTL458riX3ulj9tS/f2qz4/vUb9r1al3qOHRxoYa9VKeMUvkm9Ef3nUxyjXivQrYeU49lDljfV+en89vfm/du6Qc5myN+uZQXm7thKq8sWCC2kM5J8l9p15FzgdtRRJV4EfKGU8tvBD5RSLkyyI/XH1rFJdiqlXFBKOTbJZ6lXkventlzcRO2WsCvwmrJilKfvUUdBeRQrms2hBhYvBX7brvb01tl12YdQRyD5cpLXUbs4vahtV1fr9AUgt2bFg+QeSr0ZcconGSfZj9oC8F3qVavNqaMAnVrq8xSg3vj84iT/Qr16fWUp5cxZlK/fbYHDknyEOvrKO6h90D/Zl+dzwBuSvB44ntqK84why+pUrlLKz9ux2LddYf4Rdd+8EfhsKeW02WxAx302zBupfduPSB0i9DbU4PMKZm5BmMqzqFfCT0zy36x4kNy9qaMdrU0drWxO90HzC+DxSb5JbWG5YCDoXhUzHvtSyo1J3kS9+v5paleSzaitMWdTu7p0Xl6SJ1BHuDmMek5Zn3o8r2TlwHYlpZTLWzenw4FT2v7vPUhuO+r/8aHU4/MZ6o/MY1KfD/EzauvAVtSHQP5TKeWarjspyUf7yncJdXCJZ7HiHqveth+U5H3U0XgewMAP7tbt7gBqy8U51B/pe1FHUOryILfN2rlnDWrXse2pA0MEeGIp5S8t3y+pP5zfluRG6g/wqR6wN/R7leR44JVJLqQGbs9hbrs+vol6nv5ekg9QW4U2pP7YvkcppfdU6W9SRwI8nbrPnsLwH/9TnZ++Qf2f/98k+1CDo1dTu7vOWVnn4NhKc6+MwZ3cvibzRa2UD6dWRtdSn0T9U+oJeJ2+fHvRRmHqS9uYeq/EWcBmLW0N6lN/f9aWd0V7/25q60H/un9C30hLLa03QtPBQ8raadnUeziOBK6hjqxxALWl4+aRhKbZHwezYkSRm6g/Kn5JHaVj+yH59+pfLvVq7FHUq4XXUft1f5yVR8a5cyvfle2zx061jwfKdV7f9JYt74uB/dt2XkP9QX33gc/equ2DC9s6P0/9QXbzyDkdy7VlX961qX2vz6f+eDm/Ta89pIzPGyjPji19x677bJrjtQv1R99f2vfhq8C9BvJ0GoWpL/9tqMNI/pT6/3Ad9Sr9AdQfE3O+D1raw6itKtey8sg+Ux37LsvsdOxb3j2o/0/XUbt0fArYdLbfJWrA/Xlq8HAt9bt5JPCQjvv/btRRkXo3915Fvcl5b+B2A2XZF/hVy3d5y7cvbWSuvn3y6Bn+b5dRR/m5pC3rXGpLY//61qD+0Dyf+r92FDVg6T9WG1MvYpzV8lxObcF5bIft7h/N6K/UH/U/oI7stdGQ/A9s86+hDpywH/A8bvm/OtX3akvqj+8r23Z/gPq/uNJ3aIqy7tvyrTVDvs2pLUu/pwbiF1JHNtqjL8+dqMHZH9vrM9T7MTqdn9q8h7djf03b93vQ8f+ma1lX59j68jWqV28YOUmSJEmakfdASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQkMlOTjJEXOwnH2TnDEXZZphPVsmKUm2HfW6Jl2SvZJcNaJlH5vkA33T5yV51YjWNbLtkCbBfNYTc7Uujc4o6/vBuqDV908b0brm5XfLYmcAsQi0E+e+87zalwF79JVhpR92Y+h3wKbAqV0/kGTHJOfNkOe8dqLqf/1pNcs6uI4F37dtX/S276Ykf05yWpIDktx9IPvngXt0XO5sA7unAK+dTdk7lmNYZdN5O6RxZz0xd9rFhWNnyDNYL5QkneufjuUY2QWUWZRhr77tuzHJn5KclORtSTYeyP5fwCM6LrdX59ypY1EeDHxwNmXvUIap6qfO2zHJ1lroAmg8lVKuWOgyzEYp5UbgohEtfj/gQ33TN41oPastydqllL+uxiL+DrgcuA3wAODlwOlJHl9KOQ6glPIX4C+rXdg+SdYppVxfSrl8Lpc7nVFshzRJFls9MQLPB/pbRVbn3DsySdYA0urJVXENsBUQ4HbUH/OvAZ6f5BGllF8ClFKuAua0Vbevbrh0Lpc7nVFsx1JkC8QilGSdJG9Pcn6S65L8Jsl/tHlrJvl4knOT/CXJ2Ule3U4gvc8fnOSIJG9IcnGSq5J8Isl6g3l676nR+Ev6rkRs2WVdHbdn/SSfbOW4OMlrW/kO7suzR5ITk1yZ5JIkX0yyWd/8la4k9F3deFSSnyS5pl012XoVdvmVpZSL+l6X9K13gyQfbWW6Mslx/VczktwxyWeTLG/76OdJnt03f6p9e4urM9Ns465JTkhyPfDYNu+JSU5Ocm07Pm9Lsk6Hbb2kbeM5pZQvATsCPwUOSrJmW/ZKXX+SbJHkq0kub/v5V0l2b7PPbX9PbGU9trfd7Ri/JslyYHlLH3YF8zZJPt2+Hxdl4IpchrQupO/KXVa0Mn2x5T1v2Ha0tBcmOSfJ9e3v84es6wXt+3d1+9/bA2nMZInVE0O2b90k729luzbJ8Uke3jd/7SQHJrmgbf/vkryzb/5TUltZ/9LOXccl2WSWxfjTQN1wWd/yN0vyuSR/bK+vJ7ln3/yt2nnzonYuOSXJE/rmHwvcDXhPb3+29GHnrZXqi16eVjecAVwP3KfNe3aSX7R9dlaS/+xwLErbvgtLKWeWUj4NPBT4E/DhvnKs1PUnyd8nOSa1RfvKJD9LslOSLYHvtmyXtrIf3NvuJB9K8l9JLgV+2NKHtcbcue3Xa9r3vL81bGjrQlauL6aqnwa3Y40kb2zfoeuSnJ5ktyHremqSo1t5fpHkMTPs10XNAGJxOgTYE3gF9aTwXOo/MtRj+nvgn9u81wOvA549sIxHUK8wPwp4KrAz8K4p1vcy4MfAJ6jdhDaldhnquq6ZvLeV58nAI1u5/nEgzzrAPm3eE4A7AZ/tsOx3AHsDWwOXAZ9JklmWb6i2nK8Dm7UyPQj4HvCdJJu2bLcCTmnz/w44APhIkke1+VPt29l4F/AG4N7AT5I8FvgM8IG2zucATwPePtttbFes3kft6vOgKbJ9ELg1sFNb38tZ8X3crv3dhbptT+n73COA+7d5j2JqrwB+ST2G+wBvT/KUafIPenD7+/xWhgcPy5TkydR99n7gftRj9cEkTxzI+ibgq9Tv4uepwdXdZlEeaT4stXpi0LuBf6Ge3x4EnA58s+/c+x/UOmV34J4t75kASe4MfI66j+4D7AB8ajXLc7Mkt6b+QL6Wug8fClwIfLvNg9rK+w3gMdR9/CXgy0nu3eY/hXphZT9W7M/ZuBW1XnghcF/g/NQLIm+nnsPuA7yS2pLw4tluY7tK/2FghyQbTZHt/6jbvR31GO1L3Se/o36foNYZm1K/Pz17UFs7/pH6HZ7Km4HDgQcCHwU+ORgwzGC6+qnfy4D/R91Xfw98hXqsHjiQ723AgdTjeSLwuSS3mUV5FpdSiq9F9KKeCAuwyyw+807g233TB1Mrktv0pe0BXAes35fniL75xwIfWIV17QucMU3+21Cvjuzel7Y+8Efg4Gk+d++2HzZv01u26W3b9I5t+rF9n3lY/2c67rvz2n65qu/1ujbvkW16vYHPnAq8epplfg742HT7tq/8d+pLm2obnzrw2e8BbxxI+6dW1kxRplusb8i+/uc2vRdwVd/804B9pljuSmUe+A5eCqw7kL7Svmj7/+iBPB8DftA3XYCnDTlur5ohz+B2/BA4aEg5B9f1jr7ptajN+3t0/U758jXqF0usnhhcF7WOuB7Ys2/+msCvgbe26QOBY4ad86gXIwpwt9XYx4XaBbK/bnhmm/cc4Oz+dbfyXdY7j06xzOOBN/RNr3Qea2krnbda2o70nb9bngJsM5Dvt8CzBtJeDvximjLdYn1983Zp69lu2HEE/gwsm+KzK5V54Dt02pD8K+2L9tn/HcjzbeDT7f2WDK97bq4LpskzuB2/B940pJyD63ph3/zNWtrDV/U7Nu4v74FYfB5E7YP/3akyJHkR8Dxq8+d6wNrA+QPZTiv1CkLPj6lX+bei/iDspOO6enn/kXrFpeeFwBntMyf0EkspV2dgBITUrkf7UK803IF6dQLgrrTuL1Po35YL2t+NZ/jMoP2Bj/dN9/rpb0O98n7pQKPGraj7kdRuP3tTr35tBqxL3c/HzmL9MzlpYHobYLskr+lLW4N6fO5MvSI0G72NK1PMPwD4cJJdqBX2V0opJ3dY7hmllOs65PvxkOnZtEB0dR/goIG0HwBPGki7+TtVSrmhNbMP3kwoLaQlVU+UUj4zkG2rtowf9hJKKTcm+TH1ajvUgONo4Kwk3wKOBL5RSrkJ+Bn1x+YZbd63gUPL7PvZ/z/gm33TF7e/2wB3B64cqBtuzYq6YX1qnfYE6tXvtal1R+f9OoMb6BtUpLUSbEFtAe+/p28tVpzjZ2umumF/4GNJllHrhi+VUn7VYbld6g8YXjc8vuNnO0lyO+Au9H3Xmh8Auw6kTfV7Y0kygFh8pv1HT/Iv1C4YrwJ+RL0C8BJqU+7cFmT26zqJGgD0XEw7mTL1Cah3oj2KepJ/FnAJtQvT96mV2XT6b2rrrWO2XfcuK6WcMyR9Deo2DHa3grovoO6bV1KbQE+nXqV6OzOfVHo3avcf77WnyHv1kHK9GfjikLyrciNar0L+zbCZpZSPJzmKejJ9NPCjJO8opew7w3IHy72qCrf8v5hqX3VZ1kxpgzdKFuwOqvGy1OqJWyy2/Z3y/7WUckrra78LtbX4EOBnSR7Tgo2dge2p3bKeC7wj9Ybgn3XfOi6apm44ldp9alDvAtR/tbK9itpacQ3wSWau026i2/nuurLyTdO9c9SLqMdhLtyXur/PGzazlLJvks8Aj6Pen7dPkheVUgYv1Ayai7rhFnVoklWtF2CWdUMppbTgccnWDQYQi88p1C/kTqx85aPn4cBPSin9Y+lvNSTf3ydZv5TS+0fdntok/Osp1ns9tQl2VdYF3DzqzUon2yTnUP/ptqPd0NT6iN6vryz3pgYMryul9PKM4gr0bJ0CbALcVEoZ+uOauo++Vkr5FNx838TfsqIvMgzft70f+pv2vR/sbzldue49RcU2K60F5eXUYzHlEIWllOXUPqgfbS0fL6M2A1/fsgxu32xsP2T6l33Tl9LXPzj1RsjB/sJ/7VCGX1KPV3/l9nDgF7MprDQGllQ9McQ5bV0Pp13YaOeqh1L73feWdSX1QsoX2026xwN/A5xVaj+THwM/TrIf8HNqS/FsAoipnAI8A/hDKWWqYb8fDnyy1MEqSNJruT6rL89UdcOtk9yulNK7UDVj3VBKuTjJ74GtSimf7L4pw7W+/S8Cjpuu5aaUcjY1QDqwtXw8j3qOnau64aCB6V7d0F+H9gzupxnLUEr5c5ILqMfrO32zJr5uMIBYZEopZyf5ArVZ8GXUE9XmwJbtR+pZwF5JHkc9ye5OvYnrjwOLWot68+d+1Oa5d1L7E04V+Z9H7RazJfUq+uWzWNd023NVkoOAdyX5A7V7zRuolV8vuv8ttd/tS5P8D7WryVu6rmOEvk1t1vxqklcDv6J2EdqF2r/3+9R99C+po4P8Afh3atP2T/uWcx633LfnUG802zfJ3tQ+lm/oWK79gCOSnA98gdqUfT9qP9VXz/DZjZOsRb035f7Af1K7Q+xaphgCMMkB1C4HZ1GH+NuFFSfWS6j9hB+bOvrRtWX2Qz9un+S1wKHUfrN7As/sm/8d6sgvPwJupLbwXDuwjPOARyU5jnplbth39D3UHxonA99q2/FMRtNdShqZpVZPDNm+q9uP0Xe2euNc6rlqE9qzApK8glqfnEq9gPCv1NaP5Um2p7aWHkVt4XgQtXvPXP0g/Ay1ZeGrSd5ErcO2AHYDPtx+VJ8FPDnJV1v59qF2Yep3HvCPST5NPW/9AfgJ9Qr9O5K8j3rDbteboPcF/jv1WUZHUlsutgY2K6W8Y5rPpd14DrABK4Zx3YBbdvHsfWA9aivLF9t2bEILJluW86l1/OOTfA34y0B3uS6ekuREapfgp1Fv9n8I1EA0yfHAa5L8upV1cBu71k/vAfZLcja1e9Ue1J4H28yyvEvKkm1aWeL2pF5lOZD6o/Vg6j8HwEeoPxr/jzoKwJbUUY4GHUe94vJd6ogC3wGm+3H5X9Ro/RfUyP6us1jXTF5F7Y50eCvPadRm7GsB2tWNZdQbgX9BPdG+YhXWM6faFaxdqfvuf6kjfHwBuBcr+j++lXp/xzeoNzdfTa1c+t1i35b6LIfdqaMf/YzaJel1Hct1FLVRkIAnAAAgAElEQVQf6E5t3SdQ78P4bYeP/5xa6f6UGoj8FLh/KeV703xmDeC/W/mPplbIy1pZbqCOhvI86j75apdtGLA/NZj5KXV/vqmUcmjf/FdSr0IeSw0yPkatGBjIsxM1KPspQ5RSDqMGeP/ZtuVlwItLKV9bhTJLC22p1RODXtOW+wlqkHB/6k3jvXu8rqTeo3ACNYB6IPC4Uso1wBXUQTWOoF4dfy/wllKHJ11tbR07UM9LX6Tu/0OADVkROL2Cep76PrV+OL697/cmauDxa9oV9VKflfNM6uhNpwMvAN7YsVwfo97g/SxqvfL99vlzZ/joran1wgXU/fkK4GvA/Up7BsQQN1K39xBq3fgVaovPK1pZfk+ty99GrTNW5QGE+1JHczoN+Dfg2aWUE/vmP6f9PZH6PVzpItws6qcDqUHEu6n3bT6ZOnjJnD44cLFJ/Q2kSdKacu9USnnCTHkXQpJ1qVcn3lNKmYuKRpI0C+NeT0haWHZh0oJL8iBqt6QTgNtSryzdljrGviRJksbIgnVhSvKZJGcmOSPJQb2741MdmPoU2NPS9+TgJMtSn2J5dhsWrJe+TeqTAc9pn52TB4VpXr2C2rXkO9S+kju0G3MlTRjrB0kabyPrwpRkwyluVOzN35UVYz3/H/C9UsqHWvq/U/uWPwQ4oJTykCR3oPaL35Z6483J1Iek/DHJCdT+ysdTbww6sJTyDSRJY8f6QZIWt1G2QJyU5P+SPHLYFZ9SypGloXZd2bzN2o06tFkppRwP3D710fSPpT6R9vJW8RwN7NLm3a6U8uO2rE9Sb7aVJI0n6wdJWsRGeQ/E31IfHvJS4H+SfAo4uJRyQX+m1jT9LOoVIqhP6/1dX5blLW269OVD0m8hyQuoIw6w/vrrb3Pve9971ht18mWXzSr/Nne846zXIUmjdPLJJ/+hlLLRAhZhrOqHuagbwPpB0uLXtX4YWQDRxow/gjoe/UbU8Xd/m+QfSikn9GX9ILV5ujd82bD+qcOeNDtT+rAyfZT6sCu23XbbctJJJ3Xaln455JBZ5T9p2bKZM0nSPGrPCFkw41Y/zEXdANYPkha/rvXDSG+iTrJBu7JzOPWK03Op4/X25u8DbMTKY/ovp4573LM5dXze6dI3H5IuSRpT1g+StHiNLIBoT048hfogrD1LKTuUUg4ppVzb5j+P2m/1GaWUm/o+ejiwZxttY3vgivZgmKOAnZNsmGRDYGfgqDbvyiTbt760e7JqD6uSJM0D6wdJWtxGeQ/EF4C92pP+hvkw9WFhP2730H25lLIfdZSMXamPvL8GeDbUpy8meQv1iYIA+7UnMkJ9AuHBwHrUkTscYUOSxpf1gyQtYqO8B+LwGeYPXXcbKeMlU8w7CDhoSPpJwP1WoZiSpHlm/SBJi9uCPUhOkiRJ0uJjACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2YIFEEkOSnJJkjP60vZN8vskp7bXrn3zXpvknCRnJnlsX/ouLe2cJHvP93ZIkuaW9YMkjbeFbIE4GNhlSPr7SikPbK8jAZLcF9gd+Lv2mQ8mWTPJmsD/AI8D7gs8o+WVJC1eB2P9IElja62FWnEp5XtJtuyYfTfgc6WU64Bzk5wDbNfmnVNK+Q1Aks+1vL+Y4+JKkuaJ9YMkjbcFCyCm8dIkewInAa8spfwR2Aw4vi/P8pYG8LuB9IfMSyk7yiGHdM5bli0bYUkkadFbUvWDJC1W43YT9YeArYAHAhcC723pGZK3TJM+VJIXJDkpyUmXXnrp6pZVkjR/RlY/WDdI0uyMVQBRSrm4lHJjKeUm4H9Z0Qy9HNiiL+vmwAXTpE+1/I+WUrYtpWy70UYbzW3hJUkjM8r6wbpBkmZnrAKIJJv2TT4Z6I3AcTiwe5J1k9wduCdwAnAicM8kd0+yDvVGusPns8ySpNGzfpCk8bFg90Ak+SywI3CnJMuBfYAdkzyQ2sx8HvBCgFLKz5N8gXrz2w3AS0opN7blvBQ4ClgTOKiU8vN53hRJ0hyyfpCk8baQozA9Y0jyx6fJ/zbgbUPSjwSOnMOiSZIWkPWDJI23serCJEmSJGm8GUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2YwBRJKHJVm/vd8jyf5J7jb6okmSxpn1gyRNpi4tEB8CrknyAODVwPnAJ0daKknSYmD9IEkTqEsAcUMppQC7AQeUUg4AbjvaYkmSFgHrB0maQGt1yHNlktcCewA7JFkTWHu0xZIkLQLWD5I0gbq0QPwLcB3w3FLKRcBmwHtGWipJ0mJg/SBJE2jGFohWKezfN/1b7OMqSRPP+kGSJtOUAUSSK4Ey1fxSyu1GUiJJ0lizfpCkyTZlAFFKuS1Akv2Ai4BPAQGeiTfJSdLEsn6QpMnW5R6Ix5ZSPlhKubKU8udSyoeAp466YJKksWf9IEkTqEsAcWOSZyZZM8kaSZ4J3DjqgkmSxp71gyRNoC4BxL8C/wxc3F5Pb2mSpMlm/SBJE2jaUZjamN5PLqXsNk/lkSQtAtYPkjS5pm2BKKXcSH3CqCRJN7N+kKTJ1eVJ1D9M8gHg88DVvcRSyikjK5UkaTGwfpCkCdQlgPiH9ne/vrQCPHLuiyNJWkSsHyRpAnV5EvVO81EQSdLiYv0gSZNpxlGYkmyQZP8kJ7XXe5NsMB+FkySNL+sHSZpMXYZxPQi4kjpU3z8DfwY+McpCSZIWBesHSZpAXe6B2KqU0v9k0TcnOXVUBZIkLRrWD5I0gbq0QPwlycN7E0keBvxldEWSJC0S1g+SNIG6tED8G3BIX7/WPwJ7jaxEkqTFwvpBkiZQl1GYTgUekOR2bfrPIy+VJGnsWT9I0mTqMgrT25PcvpTy51LKn5NsmOSt81E4SdL4sn6QpMnU5R6Ix5VS/tSbKKX8Edh1dEWSJC0S1g+SNIG6BBBrJlm3N5FkPWDdafJLkiaD9YMkTaAuN1F/GjgmySeAAjwHOGSkpZIkLQbWD5I0gbrcRP3uJKcBjwYCvKWUctTISyZJGmvWD5I0mbq0QAD8ErihlPLtJLdOcttSypWjLJgkaVGwfpCkCdNlFKbnA4cCH2lJmwGHjbJQkqTxZ/0gSZOpy03ULwEeBvwZoJRyNrDxKAslSVoUrB8kaQJ1CSCuK6Vc35tIshb1ZjlJ0mSzfpCkCdQlgDguyeuA9ZI8Bvgi8LXRFkuStAhYP0jSBOoSQOwNXAqcDrwQOBJ4wygLJUlaFKwfJGkCdRnG9Sbgf9sLgCQPA344wnJJksac9YMkTaYpA4gkawL/TB1V45ullDOSPAF4HbAe8KD5KaIkaZxYP0jSZJuuBeLjwBbACcCBSc4HHgrsXUpxmD5JmlzWD5I0waYLILYF7l9KuSnJrYA/AH9TSrlofoomSRpT1g+SNMGmu4n6+ta/lVLKtcBZVg6SJKwfJGmiTdcCce8kp7X3AbZq0wFKKeX+Iy+dJGkcWT9I0gSbLoC4z7yVQpK0mFg/SNIEmzKAKKWcP58FkSQtDtYPkjTZujxITpIkSZIAAwhJkiRJszBlAJHkmPb3XaNaeZKDklyS5Iy+tDskOTrJ2e3vhi09SQ5Mck6S05Js3feZZS3/2UmWjaq8kqTR1w/WDZI03qZrgdg0ySOAJyV5UJKt+19ztP6DgV0G0vYGjiml3BM4pk0DPA64Z3u9APgQ1EoF2Ad4CLAdsE+vYpEkjcSo64eDsW6QpLE13ShMb6KeoDcH9h+YV4BHru7KSynfS7LlQPJuwI7t/SHAscBrWvonSykFOD7J7ZNs2vIeXUq5HCDJ0dSK57OrWz5J0lAjrR+sGyRpvE03CtOhwKFJ3lhKecs8lmmTUsqFrQwXJtm4pW8G/K4v3/KWNlW6JGkEFqh+sG6QpDExXQsEAKWUtyR5ErBDSzq2lHLEaIs1VIaklWnSb7mA5AXUJm7uete7zl3JJGkCjUn9YN0gSfNsxlGYkrwDeBnwi/Z6WUsblYtb8zPt7yUtfTmwRV++zYELpkm/hVLKR0sp25ZStt1oo43mvOCSNEnmuX6wbpCkMdFlGNfHA48ppRxUSjmI2of08SMs0+FAb7SMZcBX+9L3bCNubA9c0ZqzjwJ2TrJhu0Fu55YmSRqt+awfrBskaUzM2IWpuT1weXu/wVytPMlnqTe63SnJcuqIGe8EvpDkucBvgae37EcCuwLnANcAzwYopVye5C3AiS3ffr2b5iRJIzfn9YN1gySNty4BxDuAnyb5LrVP6Q7Aa+di5aWUZ0wx61FD8hbgJVMs5yDgoLkokySps5HUD9YNkjTeutxE/dkkxwIPplYQrymlXDTqgkmSxpv1gyRNpk5dmFp/0sNHXBZJ0iJj/SBJk6fLTdSSJEmSBBhASJIkSZqFaQOIJGskOWO+CiNJWhysHyRpck0bQJRSbgJ+lsRHc0qSbmb9IEmTq8tN1JsCP09yAnB1L7GU8qSRlUqStBhYP0jSBOoSQLx55KWQJC1G1g+SNIG6PAfiuCR3A+5ZSvl2klsDa46+aJKkcWb9IEmTacZRmJI8HzgU+EhL2gw4bJSFkiSNP+sHSZpMXYZxfQnwMODPAKWUs4GNR1koSdKiYP0gSROoSwBxXSnl+t5EkrWAMroiSZIWCesHSZpAXQKI45K8DlgvyWOALwJfG22xJEmLgPWDJE2gLgHE3sClwOnAC4EjgTeMslCSpEXB+kGSJlCXUZhuSnII8BNq0/SZpRSbqCVpwlk/SNJkmjGASPJ44MPAr4EAd0/ywlLKN0ZdOEnS+LJ+kKTJ1OVBcu8FdiqlnAOQZCvg64AVhCRNNusHSZpAXe6BuKRXOTS/AS4ZUXkkSYuH9YMkTaApWyCSPKW9/XmSI4EvUPu4Ph04cR7KJkkaQ9YPkjTZpuvC9MS+9xcDj2jvLwU2HFmJJEnjzvpBkibYlAFEKeXZ81kQSdLiYP0gSZOtyyhMdwf+HdiyP38p5UmjK5YkadxZP0jSZOoyCtNhwMepTxe9abTFkSQtItYPkjSBugQQ15ZSDhx5SSRJi431gyRNoC4BxAFJ9gG+BVzXSyylnDKyUkmSFgPrB0maQF0CiL8HngU8khVN1KVNS5Iml/WDJE2gLgHEk4F7lFKuH3VhJEmLivWDJE2gLk+i/hlw+1EXRJK06Fg/SNIE6tICsQnwqyQnsnIfV4fpk6TJZv0gSROoSwCxz8hLIUlajKwfJGkCzRhAlFKOm4+CSJIWF+sHSZpMXZ5EfSV1VA2AdYC1gatLKbcbZcEkSePN+kGSJlOXFojb9k8n+Sdgu5GVSJK0KFg/SNJk6jIK00pKKYfhGN+SpAHWD5I0Gbp0YXpK3+QawLasaLKWJE0o6wdJmkxdRmF6Yt/7G4DzgN1GUhpJ0mJi/SBJE6jLPRDPno+CSJIWF+sHSZpMUwYQSd40zedKKeUtIyiPJGnMWT9I0mSbrgXi6iFp6wPPBe4IWEFI0mSyfpCkCTZlAFFKeW/vfZLbAi8Dng18DnjvVJ+TJC1t1g+SNNmmvQciyR2AVwDPBA4Bti6l/HE+CiZJGl/WD5I0uaa7B+I9wFOAjwJ/X0q5at5KJUkaW9YPkjTZpmuBeCVwHfAG4PVJeumh3iR3uxGXTZI0nqwfNBFyyCGd85Zly0ZYEmm8THcPxKyfUi1JWvqsHyRpslkJSJIkSerMAEKSJElSZwYQkiRJkjqbdhhXjbfZ3NwF3uAlSZKk1WcLhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktTZ2AYQSc5LcnqSU5Oc1NLukOToJGe3vxu29CQ5MMk5SU5LsvXCll6SNArWDZK08MY2gGh2KqU8sJSybZveGzimlHJP4Jg2DfA44J7t9QLgQ/NeUknSfLFukKQFNO4BxKDdgEPa+0OAf+pL/2Spjgdun2TThSigJGneWTdI0jwa5wCiAN9KcnKSF7S0TUopFwK0vxu39M2A3/V9dnlLW0mSFyQ5KclJl1566QiLLkkaEesGSVpgay10AabxsFLKBUk2Bo5O8qtp8mZIWrlFQikfBT4KsO22295iviRp7Fk3SNICG9sWiFLKBe3vJcBXgO2Ai3vNz+3vJS37cmCLvo9vDlwwf6WVJM0H6wZJWnhjGUAkWT/JbXvvgZ2BM4DDgWUt2zLgq+394cCebcSN7YEres3ZkqSlwbpBksbDuHZh2gT4ShKoZfy/Uso3k5wIfCHJc4HfAk9v+Y8EdgXOAa4Bnj3/RZYkjZh1gySNgbEMIEopvwEeMCT9MuBRQ9IL8JJ5KJokaYFYN0jSeBjLLkySJEmSxpMBhCRJkqTOxrILkyRJ0lzLIYfMnEnSjGyBkCRJktSZLRCSJEmrabatG2XZspkzSWPKFghJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2VoLXQBJUpVDDplV/rJs2YhKIknS1GyBkCRJktSZAYQkSZKkzgwgJEmSJHXmPRBjZLb9nyVJkqT5ZguEJEmSpM4MICRJkiR1ZgAhSZIkqTPvgZAkSYuS9w5KC8MWCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZozBJkiSNudmMOFWWLRthSSRbICRJkiTNgi0QkiRJ88xnWGgxswVCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdeYoTJoTsx1NwjGqJUmSFidbICRJkiR1ZgAhSZIkqTO7MEmSJC0hdivWqBlAaCifkClJkqRh7MIkSZIkqTMDCEmSJEmdLZkuTEl2AQ4A1gQ+Vkp55wIXSZI0BqwfFhe70Erjb0kEEEnWBP4HeAywHDgxyeGllF8sbMkkSQtpUusHb6KVNEpLIoAAtgPOKaX8BiDJ54DdgCVdQUiSZjS29cNsfuQv5h/4tigsPZPy3dXUlkoAsRnwu77p5cBDFqgsmmOjvpLmiVBa0qwf5pgBgWZjMbeGLeayj1pKKQtdhtWW5OnAY0spz2vTzwK2K6X8+0C+FwAvaJP3As5chdXdCfjDahR3sZiU7YTJ2Va3c+lZ1W29Wyllo7kuzDjqUj/MUd0Ak/Xdm4n7YgX3xQruixXGdV90qh+WSgvEcmCLvunNgQsGM5VSPgp8dHVWlOSkUsq2q7OMxWBSthMmZ1vdzqVnkrZ1NcxYP8xF3QAej37uixXcFyu4L1ZY7PtiqQzjeiJwzyR3T7IOsDtw+AKXSZK08KwfJGmOLYkWiFLKDUleChxFHabvoFLKzxe4WJKkBWb9IElzb0kEEACllCOBI+dhVavdzL1ITMp2wuRsq9u59EzStq4y64cF4b5YwX2xgvtihUW9L5bETdSSJEmS5sdSuQdCkiRJ0jwwgJiFJLskOTPJOUn2XujydJFkiyTfTfLLJD9P8rKWfockRyc5u/3dsKUnyYFtG09LsnXfspa1/GcnWdaXvk2S09tnDkyS+d/Sm8uyZpKfJjmiTd89yU9amT/fbqIkybpt+pw2f8u+Zby2pZ+Z5LF96WNx/JPcPsmhSX7VjutDl+LxTPKf7Tt7RpLPJrnVUjmeSQ5KckmSM/rSRn4Mp1qHVt+4nB9GadTf28Ui81CvLhbtvHxCkp+1ffHmlj5n5+rFJiP8HTJWSim+OryoN9/9GrgHsA7wM+C+C12uDuXeFNi6vb8tcBZwX+DdwN4tfW/gXe39rsA3gADbAz9p6XcAftP+btjeb9jmnQA8tH3mG8DjFnB7XwH8H3BEm/4CsHt7/2Hg39r7FwMfbu93Bz7f3t+3Hdt1gbu3Y77mOB1/4BDgee39OsDtl9rxpD7861xgvb7juNdSOZ7ADsDWwBl9aSM/hlOtw9dqH8+xOT+MeDtH+r1dLC/moV5dLK+2Tbdp79cGftK2cU7O1Qu9fau4T0byO2Sht+sW27nQBVgsr1YZH9U3/VrgtQtdrlXYjq8Cj6E+KGnTlrYpcGZ7/xHgGX35z2zznwF8pC/9Iy1tU+BXfekr5ZvnbdscOAZ4JHBEO7H9AVhr8BhSR2R5aHu/VsuXwePayzcuxx+4HfWHdQbSl9TxZMXTg+/Qjs8RwGOX0vEEtmTlH2IjP4ZTrcPXah/LBf8+zeO2juR7u9DbtZr7ZE7r1YXentXYD7cGTqE+6X1OztULvU2rsA9G9jtkobdt8GUXpu56P2h6lre0RaM1jz2IeoVgk1LKhQDt78Yt21TbOV368iHpC+H9wKuBm9r0HYE/lVJuaNP9Zbt5e9r8K1r+2W7/fLsHcCnwidZE+rEk67PEjmcp5ffAfwG/BS6kHp+TWXrHs998HMOp1qHVM47fp/kyV9/bRWlE9eqi0rrsnApcAhxNvWI+V+fqxWaUv0PGigFEd8P6gS+aIayS3Ab4EvDyUsqfp8s6JK2sQvq8SvIE4JJSysn9yUOylhnmjfV2Uq9SbA18qJTyIOBqalP5VBbldra+w7tRm2/vAqwPPG5I1sV+PLtYytu2VLjPb2nJfz9HWK8uKqWUG0spD6Refd8OuM+wbO3vkt0X8/A7ZKwYQHS3HNiib3pz4IIFKsusJFmbepL7TCnlyy354iSbtvmbUq8cwNTbOV365kPS59vDgCclOQ/4HLX58P3A7ZP0nnfSX7abt6fN3wC4nNlv/3xbDiwvpfykTR9KDSiW2vF8NHBuKeXSUspfgS8D/8DSO5795uMYTrUOrZ5x/D7Nl7n63i4qI65XF6VSyp+AY6n3QMzVuXoxGfXvkLFiANHdicA9293061BveDl8gcs0oyQBPg78spSyf9+sw4Fl7f0yah/OXvqebdSI7YErWlPsUcDOSTZsV4d3pvbjuxC4Msn2bV179i1r3pRSXltK2byUsiX12HynlPJM4LvA01q2we3sbf/TWv7S0ndvoyPcHbgn9YbUsTj+pZSLgN8luVdLehTwC5bY8aR2Xdo+ya1bOXrbuaSO54D5OIZTrUOrZxy/T/NlTr63813o1THqenVeNmKOJNkoye3b+/WoF39+ydydqxeNefgdMl4W+iaMxfSijqRwFrV/3+sXujwdy/xwatPXacCp7bUrtZ/dMcDZ7e8dWv4A/9O28XRg275lPQc4p72e3Ze+LXBG+8wHGLjBdwG2eUdWjH5wD+o/3jnAF4F1W/qt2vQ5bf49+j7/+rYtZ9I3AtG4HH/ggcBJ7ZgeRh29Y8kdT+DNwK9aWT5FHZFiSRxP4LPUezv+Sr3a9Nz5OIZTrcPXnBzTsTg/jHgbR/q9XSwv5qFeXSwv4P7AT9u+OAN4U0ufs3P1Ynwxot8h4/TySdSSJEmSOrMLkyRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEJaDUmOTfLYgbSXJ/ngNJ+5avQlkyQtJOsHLWUGENLq+Sz1gTH9dm/pkqTJZf2gJcsAQlo9hwJPSLIuQJItgbsApyY5JskpSU5PstvgB5PsmOSIvukPJNmrvd8myXFJTk5yVJJN52NjJElzxvpBS5YBhLQaSimXUZ8guUtL2h34PPAX4MmllK2BnYD3JkmXZSZZG/hv4GmllG2Ag4C3zXXZJUmjY/2gpWythS6AtAT0mqm/2v4+Bwjw9iQ7ADcBmwGbABd1WN69gPsBR7c6ZU3gwrkvtiRpxKwftCQZQEir7zBg/yRbA+uVUk5pTc0bAduUUv6a5DzgVgOfu4GVWwF78wP8vJTy0NEWW5I0YtYPWpLswiStplLKVcCx1Kbk3s1xGwCXtMphJ+BuQz56PnDfJOsm2QB4VEs/E9goyUOhNlkn+btRboMk6f+3c8coCMRAGEb/AY/owcQ7iGBh4zUERRAES29hExtBsJpiRZT3ykBgtxo+EjI984F/5QQCprFOss3rxY1Vkl1V7SUm4XQAAABkSURBVJMck1zeN4wxblW1SXJKck1yeK7fq2qeZPkcHLMkiyTnj/8FAFMzH/g7Ncb49jcAAAA/whUmAACgTUAAAABtAgIAAGgTEAAAQJuAAAAA2gQEAADQJiAAAIA2AQEAALQ9AGaz6XodUMKrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividindo os dados entre features e coluna alvo\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n",
    "\n",
    "# Visualizando os principais desvios das colunas contínuas entre os dados\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para atributos com distribuição muito distorcida, tais como `'capital-gain'` e `'capital-loss'`, é uma prática comum aplicar uma <a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">transformação logarítmica</a> nos dados para que os valores muito grandes e muito pequenos não afetem a performance do algoritmo de aprendizado. Usar a transformação logarítmica reduz significativamente os limites dos valores afetados pelos outliers (valores muito grandes ou muito pequenos). Deve-se tomar cuidado ao aplicar esta transformação, poir o logaritmo de `0` é indefinido, portanto temos que incrementar os valores em uma pequena quantia acima de `0` para aplicar o logaritmo adequadamente.\n",
    "\n",
    "Execute o código da célula abaixo para realizar a transformação nos dados e visualizar os resultados. De novo, note os valores limite e como os valores estão distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicando a transformação de log nos registros distorcidos.\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualizando as novas distribuições após a transformação.\n",
    "vs.distribution(features_log_transformed, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando atributos numéricos\n",
    "Além das transformações em atributos distorcidos, é uma boa prática comum realizar algum tipo de adaptação de escala nos atributos numéricos. Ajustar a escala nos dados não modifica o formato da distribuição de cada coluna (tais como `'capital-gain'` ou `'capital-loss'` acima); no entanto, a normalização garante que cada atributo será tratado com o mesmo peso durante a aplicação de aprendizado supervisionado. Note que uma vez aplicada a escala, a observação dos dados não terá o significado original, como exemplificado abaixo.\n",
    "\n",
    "Execute o código da célula abaixo para normalizar cada atributo numérico, nós usaremos ara isso a [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Inicializando um aplicador de escala e aplicando em seguida aos atributos\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Exibindo um exemplo de registro com a escala aplicada\n",
    "display(features_log_minmax_transform.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Pré-processamento dos dados\n",
    "\n",
    "A partir da tabela em **Explorando os dados** acima, nós podemos observar que existem diversos atributos não-numéricos para cada registro. Usualmente, algoritmos de aprendizado esperam que os inputs sejam numéricos, o que requer que os atributos não numéricos (chamados de *variáveis de categoria*) sejam convertidos. Uma maneira popular de converter as variáveis de categoria é utilizar a estratégia **one-hot encoding**. Esta estratégia cria uma variável para cada categoria possível de cada atributo não numérico. Por exemplo, assuma que `algumAtributo` possuí três valores possíveis: `A`, `B`, ou `C`. Nós então transformamos este atributo em três novos atributos: `algumAtributo_A`, `algumAtributo_B` e `algumAtributo_C`.\n",
    "\n",
    "\n",
    "|   | algumAtributo |                    | algumAtributo_A | algumAtributo_B | algumAtributo_C |\n",
    "| :-: | :-: |                            | :-: | :-: | :-: |\n",
    "| 0 |  B  |  | 0 | 1 | 0 |\n",
    "| 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |\n",
    "| 2 |  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "Além disso, assim como os atributos não-numéricos, precisaremos converter a coluna alvo não-numérica, `'income'`, para valores numéricos para que o algoritmo de aprendizado funcione. Uma vez que só existem duas categorias possíveis para esta coluna (\"<=50K\" e \">50K\"), nós podemos evitar a utilização do one-hot encoding e simplesmente transformar estas duas categorias para `0` e `1`, respectivamente. No trecho de código abaixo, você precisará implementar o seguinte:\n",
    " - Utilizar [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para realizar o one-hot encoding nos dados da `'features_log_minmax_transform'`.\n",
    " - Converter a coluna alvo `'income_raw'` para re.\n",
    "   - Transforme os registros com \"<=50K\" para `0` e os registros com \">50K\" para `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n",
      "['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass_ Federal-gov', 'workclass_ Local-gov', 'workclass_ Private', 'workclass_ Self-emp-inc', 'workclass_ Self-emp-not-inc', 'workclass_ State-gov', 'workclass_ Without-pay', 'education_level_ 10th', 'education_level_ 11th', 'education_level_ 12th', 'education_level_ 1st-4th', 'education_level_ 5th-6th', 'education_level_ 7th-8th', 'education_level_ 9th', 'education_level_ Assoc-acdm', 'education_level_ Assoc-voc', 'education_level_ Bachelors', 'education_level_ Doctorate', 'education_level_ HS-grad', 'education_level_ Masters', 'education_level_ Preschool', 'education_level_ Prof-school', 'education_level_ Some-college', 'marital-status_ Divorced', 'marital-status_ Married-AF-spouse', 'marital-status_ Married-civ-spouse', 'marital-status_ Married-spouse-absent', 'marital-status_ Never-married', 'marital-status_ Separated', 'marital-status_ Widowed', 'occupation_ Adm-clerical', 'occupation_ Armed-Forces', 'occupation_ Craft-repair', 'occupation_ Exec-managerial', 'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct', 'occupation_ Other-service', 'occupation_ Priv-house-serv', 'occupation_ Prof-specialty', 'occupation_ Protective-serv', 'occupation_ Sales', 'occupation_ Tech-support', 'occupation_ Transport-moving', 'relationship_ Husband', 'relationship_ Not-in-family', 'relationship_ Other-relative', 'relationship_ Own-child', 'relationship_ Unmarried', 'relationship_ Wife', 'race_ Amer-Indian-Eskimo', 'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White', 'sex_ Female', 'sex_ Male', 'native-country_ Cambodia', 'native-country_ Canada', 'native-country_ China', 'native-country_ Columbia', 'native-country_ Cuba', 'native-country_ Dominican-Republic', 'native-country_ Ecuador', 'native-country_ El-Salvador', 'native-country_ England', 'native-country_ France', 'native-country_ Germany', 'native-country_ Greece', 'native-country_ Guatemala', 'native-country_ Haiti', 'native-country_ Holand-Netherlands', 'native-country_ Honduras', 'native-country_ Hong', 'native-country_ Hungary', 'native-country_ India', 'native-country_ Iran', 'native-country_ Ireland', 'native-country_ Italy', 'native-country_ Jamaica', 'native-country_ Japan', 'native-country_ Laos', 'native-country_ Mexico', 'native-country_ Nicaragua', 'native-country_ Outlying-US(Guam-USVI-etc)', 'native-country_ Peru', 'native-country_ Philippines', 'native-country_ Poland', 'native-country_ Portugal', 'native-country_ Puerto-Rico', 'native-country_ Scotland', 'native-country_ South', 'native-country_ Taiwan', 'native-country_ Thailand', 'native-country_ Trinadad&Tobago', 'native-country_ United-States', 'native-country_ Vietnam', 'native-country_ Yugoslavia']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.829751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.742849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  0.301370       0.800000      0.667492           0.0        0.397959   \n",
       "1  0.452055       0.800000      0.000000           0.0        0.122449   \n",
       "2  0.287671       0.533333      0.000000           0.0        0.397959   \n",
       "3  0.493151       0.400000      0.000000           0.0        0.397959   \n",
       "4  0.150685       0.800000      0.000000           0.0        0.397959   \n",
       "5  0.273973       0.866667      0.000000           0.0        0.397959   \n",
       "6  0.438356       0.266667      0.000000           0.0        0.153061   \n",
       "7  0.479452       0.533333      0.000000           0.0        0.448980   \n",
       "8  0.191781       0.866667      0.829751           0.0        0.500000   \n",
       "9  0.342466       0.800000      0.742849           0.0        0.397959   \n",
       "\n",
       "   workclass_ Federal-gov  workclass_ Local-gov  workclass_ Private  \\\n",
       "0                       0                     0                   0   \n",
       "1                       0                     0                   0   \n",
       "2                       0                     0                   1   \n",
       "3                       0                     0                   1   \n",
       "4                       0                     0                   1   \n",
       "5                       0                     0                   1   \n",
       "6                       0                     0                   1   \n",
       "7                       0                     0                   0   \n",
       "8                       0                     0                   1   \n",
       "9                       0                     0                   1   \n",
       "\n",
       "   workclass_ Self-emp-inc  workclass_ Self-emp-not-inc  \\\n",
       "0                        0                            0   \n",
       "1                        0                            1   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            0   \n",
       "5                        0                            0   \n",
       "6                        0                            0   \n",
       "7                        0                            1   \n",
       "8                        0                            0   \n",
       "9                        0                            0   \n",
       "\n",
       "              ...              native-country_ Portugal  \\\n",
       "0             ...                                     0   \n",
       "1             ...                                     0   \n",
       "2             ...                                     0   \n",
       "3             ...                                     0   \n",
       "4             ...                                     0   \n",
       "5             ...                                     0   \n",
       "6             ...                                     0   \n",
       "7             ...                                     0   \n",
       "8             ...                                     0   \n",
       "9             ...                                     0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "5                            0                         0   \n",
       "6                            0                         0   \n",
       "7                            0                         0   \n",
       "8                            0                         0   \n",
       "9                            0                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "5                      0                       0                         0   \n",
       "6                      0                       0                         0   \n",
       "7                      0                       0                         0   \n",
       "8                      0                       0                         0   \n",
       "9                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "5                                0                              1   \n",
       "6                                0                              0   \n",
       "7                                0                              1   \n",
       "8                                0                              1   \n",
       "9                                0                              1   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                        0                           0  \n",
       "1                        0                           0  \n",
       "2                        0                           0  \n",
       "3                        0                           0  \n",
       "4                        0                           0  \n",
       "5                        0                           0  \n",
       "6                        0                           0  \n",
       "7                        0                           0  \n",
       "8                        0                           0  \n",
       "9                        0                           0  \n",
       "\n",
       "[10 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Utilize o one-hot encoding nos dados em 'features_log_minmax_transform' utilizando pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "# TODO: Faça o encode da coluna 'income_raw' para valores numéricos\n",
    "income = income_raw.replace({'<=50K':0, '>50K':1})\n",
    "\n",
    "# Exiba o número de colunas depois do one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Descomente a linha abaixo para ver as colunas após o encode\n",
    "print(encoded)\n",
    "\n",
    "display(features_final.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embaralhar e dividir os dados\n",
    "Agora todas as _variáveis de categoria_ foram convertidas em atributos numéricos e todos os atributos numéricos foram normalizados. Como sempre, nós agora dividiremos os dados entre conjuntos de treinamento e de teste. 80% dos dados serão utilizados para treinamento e 20% para teste.\n",
    "\n",
    "Execute o código da célula abaixo para realizar divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Importar train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os 'atributos' e 'income' entre conjuntos de treinamento e de testes.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Avaliando a performance do modelo\n",
    "Nesta seção nós investigaremos quatro algoritmos diferentes e determinaremos qual deles é melhor para a modelagem dos dados. Três destes algoritmos serão algoritmos de aprendizado supervisionado de sua escolha e o quarto algoritmo é conhecido como *naive predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas e o Naive predictor\n",
    "\n",
    "*CharityML*, equpada com sua pesquisa, sabe que os indivíduos que fazem mais do que \\$50,000 possuem maior probabilidade de doar para a sua campanha de caridade. Por conta disto, a *CharityML* está particularmente interessada em predizer com acurácia quais indivíduos possuem remuneração acima de \\$50,000. Parece que utilizar **acurácia (accuracy)** como uma métrica para avaliar a performance de um modelo é um parâmetro adequado. Além disso, identificar alguém que *não possui* remuneração acima de \\$50,000 como alguém que recebe acima deste valor seria ruim para a *CharityML*, uma vez que eles estão procurando por indivíduos que desejam doar. Com isso, a habilidade do modelo em predizer com preisão aqueles que possuem a remuneração acima dos \\$50,000 é *mais importante* do que a habilidade de realizar o **recall** destes indivíduos. Nós podemos utilizar a fórmula **F-beta score** como uma métrica que considera ambos: precision e recall.\n",
    "\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "Em particular, quando $\\beta = 0.5$, maior ênfase é atribuída para a variável precision. Isso é chamado de **F$_{0.5}$ score** (ou F-score, simplificando).\n",
    "\n",
    "Analisando a distribuição de classes (aqueles que possuem remuneração até \\$50,000 e aqueles que possuem remuneração superior), fica claro que a maioria dos indivíduos não possui remuneração acima de \\$50,000. Isto pode ter grande impacto na **acurácia (accuracy)**, uma vez que nós poderíamos simplesmente dizer *\"Esta pessoa não possui remuneração acima de \\$50,000\"* e estar certos em boa parte das vezes, sem ao menos olhar os dados! Fazer este tipo de afirmação seria chamado de **naive**, uma vez que não consideramos nenhuma informação para balisar este argumento. É sempre importante considerar a *naive prediction* para seu conjunto de dados, para ajudar a estabelecer um benchmark para análise da performance dos modelos. Com isso, sabemos que utilizar a naive prediction não traria resultado algum: Se a predição apontasse que todas as pessoas possuem remuneração inferior à \\$50,000, a *CharityML* não identificaria ninguém como potencial doador. \n",
    "\n",
    "\n",
    "\n",
    "#### Nota: Revisando: accuracy, precision e recall\n",
    "\n",
    "** Accuracy ** mede com que frequência o classificador faz a predição correta. É a proporção entre o número de predições corretas e o número total de predições (o número de registros testados).\n",
    "\n",
    "** Precision ** informa qual a proporção de mensagens classificamos como spam eram realmente spam. Ou seja, é a proporção de verdadeiros positivos (mensagens classificadas como spam que eram realmente spam) sobre todos os positivos (todas as palavras classificadas como spam, independente se a classificação estava correta), em outras palavras, é a proporção\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso positivos)]`\n",
    "\n",
    "** Recall(sensibilidade)** nos informa qual a proporção das mensagens que eram spam que foram corretamente classificadas como spam. É a proporção entre os verdadeiros positivos (classificados como spam, que realmente eram spam) sobre todas as palavras que realmente eram spam. Em outras palavras, é a proporção entre\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso negativos)]`\n",
    "\n",
    "Para problemas de classificação distorcidos em suas distribuições, como no nosso caso, por exemplo, se tivéssemos 100 mensagems de texto e apenas 2 fossem spam e todas as outras não fossem, a \"accuracy\" por si só não seria uma métrica tão boa. Nós poderiamos classificar 90 mensagems como \"não-spam\" (incluindo as 2 que eram spam mas que teriam sido classificadas como não-spam e, por tanto, seriam falso negativas.) e 10 mensagems como spam (todas as 10 falso positivas) e ainda assim teriamos uma boa pontuação de accuracy. Para estess casos, precision e recall são muito úteis. Estas duas métricas podem ser combinadas para resgatar o F1 score, que é calculado através da média(harmônica) dos valores de precision e de recall. Este score pode variar entre 0 e 1, sendo 1 o melhor resultado possível para o F1 score (consideramos a média harmônica pois estamos lidando com proporções)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Performance do Naive Predictor\n",
    "* Se escolhessemos um modelo que sempre prediz que um indivíduo possui remuneração acima de $50,000, qual seria a accuracy e o F-score considerando este conjunto de dados? Você deverá utilizar o código da célula abaixo e atribuir os seus resultados para as variáveis `'accuracy'` e `'fscore'` que serão usadas posteriormente.\n",
    "\n",
    "** Por favor, note ** que o propósito ao gerar um naive predictor é simplesmente exibir como um modelo sem nenhuma inteligência se comportaria. No mundo real, idealmente o seu modelo de base será o resultado de um modelo anterior ou poderia ser baseado em um paper no qual você se basearia para melhorar. Quando não houver qualquer benchmark de modelo, utilizar um naive predictor será melhor do que uma escolha aleatória.\n",
    "\n",
    "** DICA: ** \n",
    "\n",
    "* Quando temos um modelo que sempre prediz '1' (e.x o indivíduo possui remuneração superior à 50k) então nosso modelo não terá Verdadeiros Negativos ou Falso Negativos, pois nós não estaremos afirmando que qualquer dos valores é negativo (ou '0') durante a predição. Com isso, nossa accuracy neste caso se torna o mesmo valor da precision (Verdadeiros positivos/ (Verdadeiros positivos + Falso positivos)) pois cada predição que fizemos com o valor '1' que deveria ter o valor '0' se torna um falso positivo; nosso denominador neste caso é o número total de registros.\n",
    "* Nossa pontuação de Recall(Verdadeiros positivos/(Verdadeiros Positivos + Falsos negativos)) será 1 pois não teremos Falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.2478, F-score: 0.2917]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TP = np.sum(income) # Contando pois este é o caso \"naive\". Note que 'income' são os dados 'income_raw' convertidos\n",
    "para valores numéricos durante o passo de pré-processamento de dados.\n",
    "FP = income.count() - TP # Específico para o caso naive\n",
    "\n",
    "TN = 0 # Sem predições negativas para o caso naive\n",
    "FN = 0 # Sem predições negativas para o caso naive\n",
    "\n",
    "'''\n",
    "# np.sum(income)> verdadeiros positivos (TP)\n",
    "# ((income.count()) - np.sum(income)) > falsos positivos (FP)\n",
    "\n",
    "# TODO: Calcular accuracy, precision e recall\n",
    "accuracy = (np.sum(income)) / ((np.sum(income)) + float(((income.count()) - np.sum(income))))\n",
    "recall = np.sum(income)/float((np.sum(income)))\n",
    "precision = np.sum(income)/float(((np.sum(income) + ((income.count()) - np.sum(income)))))\n",
    "beta=0.5\n",
    "\n",
    "# TODO: Calcular o F-score utilizando a fórmula acima para o beta = 0.5 e os valores corretos de precision e recall.\n",
    "fscore = (1+beta**2)*(precision*recall)/((beta**2*precision)+recall)\n",
    "\n",
    "# Exibir os resultados \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelos de Aprendizado Supervisionado\n",
    "**Estes são alguns dos modelos de aprendizado supervisionado disponíveis em** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees (Árvores de decisão)\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação do Modelo\n",
    "Liste três dos modelos de aprendizado supervisionado acima que são apropriados para este problema que você irá testar nos dados do censo. Para cada modelo escolhido\n",
    "\n",
    "- Descreva uma situação do mundo real onde este modelo pode ser utilizado. \n",
    "- Quais são as vantagems da utilização deste modelo; quando ele performa bem?\n",
    "- Quais são as fraquesas do modelo; quando ele performa mal?\n",
    "- O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?\n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Estruture sua resposta no mesmo formato acima^, com 4 partes para cada um dos modelos que você escolher. Por favor, inclua referências em cada uma das respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "**1)Support Vector Machines (SVM)**\n",
    "\n",
    "**Descreva uma situação do mundo real onde este modelo pode ser utilizado.**\n",
    "Reconhecimento de caracteres \n",
    "\n",
    "**Quais são as vantagems da utilização deste modelo; quando ele performa bem?**\n",
    "SVM é uma técnica que separa duas únicas classes (A e B) a partir de amostras de treinamento. Ele faz isso por um processo de otmimização contínua em que busca encontrar o hiperplano que mais bem separa as duas classes. Esse hiperplano é aquele cuja distância das classes é a maior possível. Dentre suas vantagens, podemos citar: sempre encontra a melhor solução possível para o problema de otimização. É um dos mais eficientes classificadores para problemas de elevada dimensionalidade (muitos atributos) e sua técnica de relaxamento minimiza o risco de overffitting.\n",
    "\n",
    "**Quais são as fraquesas do modelo; quando ele performa mal?**\n",
    "São voltados principalmente para atributos numéricos. \n",
    "\n",
    "**O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?**\n",
    "- Os dados são rotulados\n",
    "- Trabalha com classificação\n",
    "- O tamanho da amostra é menos que 100.000\n",
    "\n",
    "**2)SGD Classifier**\n",
    "\n",
    "**Descreva uma situação do mundo real onde este modelo pode ser utilizado.**\n",
    "\n",
    "Classificação de texto e processamento de linguagem natural. É útil quando os dados fornecidos são escassos, a função pode facilmente ser dimensionada para problemas com mais de 10 ^ 5 exemplos de treinamento e mais de 10 ^ 5 recursos.\n",
    "\n",
    "**Quais são as vantagems da utilização deste modelo; quando ele performa bem?**\n",
    "- É eficiente.\n",
    "- É fácil de implementar e oferece muitas oportunidades para o ajuste de código. \n",
    "\n",
    "**Quais são as fraquesas do modelo; quando ele performa mal?**\n",
    "Um número de hiperparâmetros é necessário para o SGD, como o número de iterações e o parâmetro de regularização. Ele (SGD) é sensível ao dimensionamento de recursos.\n",
    "\n",
    "**O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?**\n",
    "\n",
    "- O tamanho da amostra é maior que 50 amostras (tem dados suficientes para treinar).\n",
    "- Os dados são rotulados.\n",
    "- O tamanho da amostra é menor que 100k, mas o SGD funciona bem com tamanhos maiores que isso, o que significa maior eficiência e velocidade computacional.\n",
    "\n",
    "**3) K Nearest Neighbour**\n",
    "**Descreva uma situação do mundo real onde este modelo pode ser utilizado.**\n",
    "O KNN pode ser usado para fornecer recomendações. Um exemplo do mundo real disso seria serviços de streaming de vídeo, como Netflix ou Amazon Prime. Se um determinado usuário gostar de um item na biblioteca, itens semelhantes de que eles possam gostar, mas não tiverem conhecimento, podem ser recomendados para eles usando dados de outros usuários e seus gostos. Se for visto que um conjunto semelhante de usuários gosta de dois itens diferentes, esses itens são provavelmente semelhantes e para cada um dos respectivos usuários, e merecem uma recomendação.\n",
    "\n",
    "**Quais são as vantagems da utilização deste modelo; quando ele performa bem?**\n",
    "Fácil de entender e implementar - não é necessário muito código. \n",
    "Nenhuma distribuição de probabilidade é assumida com base nos dados de entrada. Isso é útil com entradas em que a distribuição de probabilidade é desconhecida, tornando-a robusta. \n",
    "KNN é um aprendiz preguiçoso. Isso significa que ele generaliza os dados durante a fase de treinamento, e não na fase de testes. Isso permite que ele se adapte rapidamente às alterações, pois não espera um conjunto de dados generalizado.\n",
    "\n",
    "**Quais são as fraquesas do modelo; quando ele performa mal?**\n",
    "A KNN obtém sua informação de seus vizinhos de entrada. Como resultado disso, os outliers localizados podem afetar significativamente os resultados quando comparados com outros algoritmos que têm uma visão geral dos dados. É sensível a dados localizados. \n",
    "Um dos seus pontos fortes, o aprendizado preguiçoso, também é uma das suas fraquezas. Como a maior parte da computação é feita durante o teste, e não durante o treinamento, isso pode resultar em tempos de computação longos ao lidar com grandes conjuntos de dados. \n",
    "Se houver um tipo de categorey presente muito mais que outro, classificar um input resultará em um viés para essa categorey mais abundante. Isso pode ser resolvido ajustando os pesos com base nas ocorrências, mas ainda será um problema próximo ao limite de decisão. \n",
    "As entradas podem estar perto de muitos pontos quando há muitas dimensões. A eficácia do k-NN é reduzida como resultado. É assim que se baseia na correlação entre proximidade e semelhança. A redução de dimensão pode ser usada para reduzir os efeitos disso, mas as tendências variáveis podem ser perdidas como resultado. \n",
    "\n",
    "**O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?**\n",
    "O tamanho da amostra é maior que 50 amostras (tem dados suficientes para treinar).\n",
    "Prever uma categorey (trabalha com classificação).\n",
    "Tamanho da amostra é inferior a 100k\n",
    "Os dados são rotulados.\n",
    "\n",
    "https://pt.slideshare.net/perone/intro-ml-slides20min\n",
    "https://pt.stackoverflow.com/questions/40135/explicar-o-algoritmo-svr\n",
    "https://en.wikipedia.org/wiki/Support_vector_machine#Applications\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "Udacity lectures (Machine Learning Nano Degree)\n",
    "http://scikit-learn.org/stable/modules/sgd.html\n",
    "https://brilliant.org/wiki/k-nearest-neighbors/#pros-and-cons\n",
    "http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Criando um Pipeline de Treinamento e Predição\n",
    "Para avaliar adequadamente a performance de cada um dos modelos que você escolheu é importante que você crie um pipeline de treinamento e predição que te permite de maneira rápida e eficiente treinar os modelos utilizando vários tamanhos de conjuntos de dados para treinamento, além de performar predições nos dados de teste. Sua implementação aqui será utilizada na próxima seção. No bloco de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar `fbeta_score` e `accuracy_score` de [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Adapte o algoritmo para os dados de treinamento e registre o tempo de treinamento. \n",
    " - Realize predições nos dados de teste `X_test`, e também nos 300 primeiros pontos de treinamento `X_train[:300]`.\n",
    "   - Registre o tempo total de predição. \n",
    " - Calcule a acurácia tanto para o conjundo de dados de treino quanto para o conjunto de testes.\n",
    " - Calcule o F-score para os dois conjuntos de dados: treino e testes. \n",
    "   - Garanta que você configurou o parâmetro `beta`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300] \n",
    "    # acurácia é o número de predições corretas e o número total de predições\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train[:300], beta = 0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta = 0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Validação inicial do modelo\n",
    "No código da célular, você precisará implementar o seguinte:\n",
    "- Importar os três modelos de aprendizado supervisionado que você escolheu na seção anterior \n",
    "- Inicializar os três modelos e armazená-los em `'clf_A'`, `'clf_B'`, e `'clf_C'`. \n",
    "  - Utilize um `'random_state'` para cada modelo que você utilizar, caso seja fornecido.\n",
    "  - **Nota:** Utilize as configurações padrão para cada modelo - você otimizará um modelo específico em uma seção posterior\n",
    "- Calcule o número de registros equivalentes à 1%, 10%, e 100% dos dados de treinamento.\n",
    "  - Armazene estes valores em `'samples_1'`, `'samples_10'`, e `'samples_100'` respectivamente.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo de sua escolha, a implementação abaixo pode demorar algum tempo para executar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 361 samples.\n",
      "SVC trained on 3617 samples.\n",
      "SVC trained on 36177 samples.\n",
      "SGDClassifier trained on 361 samples.\n",
      "SGDClassifier trained on 3617 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier trained on 36177 samples.\n",
      "KNeighborsClassifier trained on 361 samples.\n",
      "KNeighborsClassifier trained on 3617 samples.\n",
      "KNeighborsClassifier trained on 36177 samples.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizado supervisionado da sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = svm.SVC(random_state = 7)\n",
    "clf_B = SGDClassifier(random_state = 7)\n",
    "clf_C = KNeighborsClassifier()\n",
    "\n",
    "# TODO: Calcule o número de amostras para 1%, 10%, e 100% dos dados de treinamento\n",
    "# HINT: samples_100 é todo o conjunto de treinamento e.x.: len(y_train)\n",
    "# HINT: samples_10 é 10% de samples_100\n",
    "# HINT: samples_1 é 1% de samples_100\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(samples_100*0.1)\n",
    "samples_1 = int(samples_100*0.01)\n",
    "\n",
    "# Colete os resultados dos algoritmos de aprendizado\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Melhorando os resultados\n",
    "Nesta seção final, você irá escolher o melhor entre os três modelos de aprendizado supervisionado para utilizar nos dados dos estudantes. Você irá então realizar uma busca grid para otimização em todo o conjunto de dados de treino (`X_train` e `y_train`) fazendo o tuning de pelo menos um parâmetro para melhorar o F-score anterior do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o melhor modelo\n",
    "\n",
    "* Baseado na validação anterior, em um ou dois parágrafos explique para a *CharityML* qual dos três modelos você acredita ser o mais apropriado para a tarefa de identificar indivíduos com remuneração anual superior à \\$50,000.  \n",
    "\n",
    "** DICA: ** \n",
    "Analise o gráfico do canto inferior esquerdo da célula acima(a visualização criada através do comando `vs.evaluate(results, accuracy, fscore)`) e verifique o F score para o conjunto de testes quando 100% do conjunto de treino é utilizado. Qual modelo possui o maior score? Sua resposta deve abranger os seguintes pontos:\n",
    "* métricas - F score no conjunto de testes quando 100% dos dados de treino são utilizados, \n",
    "* tempo de predição/treinamento \n",
    "* a adequação do algoritmo para este conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "- Considerando a métrica F score, temos que o SVC apresenta o melhor resultado, seguido pelo SGD e KNeighbours.\n",
    "- Levando em conta o tempo de treinamento, temos que o SGD e K neighbors são os que apresentam menor tempo de treino.\n",
    "- Olhando o tempo de predição, esse é maior para o Kneighbours devido a sua característica de 'aprendizado preguiçoso', seguido pelo SVC e o SGD apresenta menor tempo de modelo de predição.\n",
    "\n",
    "Enfim, o melhor algoritmo de adequação é o modelo SGD devido ao seu baixo tempo de predição/treinamento e alto fscore. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 - Descrevendo o modelo nos termos de Layman\n",
    " \n",
    "* Em um ou dois parágrafos, explique para a *CharityML*, nos termos de layman, como o modelo final escolhido deveria funcionar. Garanta que você está descrevendo as principais vantagens do modelo, tais como o modo de treinar o modelo e como o modelo realiza a predição. Evite a utilização de jargões matemáticos avançados, como por exemplo a descrição de equações. \n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Quando estiver explicando seu modelo, cite as fontes externas utilizadas, caso utilize alguma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** \n",
    "No descendente de gradiente estocástico, o modelo calcula o gradiente verdadeiro aproximando o gradiente em um único exemplo. Em cada exemplo de treinamento, ele fará uma atualização desse gradiente com base nesses exemplos individuais. Isso pode acontecer até que o algoritmo atinja a convergência. Ele tenta encontrar os mínimos ou máximos pelo processo de iteração.\n",
    "\n",
    "Passo a passo, isso será o seguinte:\n",
    "\n",
    "Após o shuffle, split e treinamento inicial usando os dados de treinamento, é feita uma estimativa inicial do gradiente (com base nos parâmetros e na taxa de aprendizado escolhida).\n",
    "O algoritmo percorrerá o conjunto de treinamento, em iterações, e em cada exemplo de treinamento, ele fará um ajuste na aproximação do gradiente. Isso é baseado no feedback que a aproximação atual obtém versus o exemplo atual de treinamento.\n",
    "Vários passes podem ser feitos no conjunto de treinamento até que o algoritmo comece a alcançar a convergência (importante para embaralhar os dados para evitar ciclos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Tuning do modelo\n",
    "Refine o modelo escolhido. Utilize uma busca grid (`GridSearchCV`) com pleo menos um parâmetro importante refinado com pelo menos 3 valores diferentes. Você precisará utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você precisará implementar o seguinte:\n",
    "- Importar [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Inicializar o classificador escolhido por você e armazená-lo em `clf`.\n",
    " - Configurar um `random_state` se houver um disponível para o mesmo estado que você configurou anteriormente.\n",
    "- Criar um dicionário dos parâmetros que você quer otimizar para o modelo escolhido.\n",
    " - Exemplo: `parâmetro = {'parâmetro' : [lista de valores]}`.\n",
    " - **Nota:** Evite otimizar o parâmetro `max_features` se este parâmetro estiver disponível! \n",
    "- Utilize `make_scorer` para criar um objeto de pontuação `fbeta_score` (com $\\beta = 0.5$).\n",
    "- Realize a busca gride no classificador `clf` utilizando o `'scorer'` e armazene-o na variável `grid_obj`.   \n",
    "- Adeque o objeto da busca grid aos dados de treino (`X_train`, `y_train`) e armazene em `grid_fit`.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo escolhido e da lista de parâmetros, a implementação a seguir pode levar algum tempo para executar! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8297\n",
      "F-score on testing data: 0.6493\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8415\n",
      "Final F-score on the testing data: 0.6861\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importar 'GridSearchCV', 'make_scorer', e qualquer biblioteca necessária\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "# TODO: Inicializar o classificador\n",
    "clf = SGDClassifier(random_state=7)\n",
    "\n",
    "# TODO: Criar a lista de parâmetros que você quer otimizar, utilizando um dicionário, caso necessário.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {'loss': ['hinge', 'log'], 'penalty': ['none', 'l2', 'l1', 'elasticnet'], 'alpha': [0.0001,0.001,0.01, 0.1, 1.0] }\n",
    "\n",
    "# TODO: Criar um objeto fbeta_score utilizando make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# TODO: Realizar uma busca grid no classificador utilizando o 'scorer' como o método de score no GridSearchCV() \n",
    "grid_obj = grid_search.GridSearchCV(estimator = clf, param_grid = parameters,scoring = scorer )\n",
    "\n",
    "# TODO: Adequar o objeto da busca grid como os dados para treinamento e encontrar os parâmetros ótimos utilizando fit() \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Recuperar o estimador\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Realizar predições utilizando o modelo não otimizado e modelar\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Reportar os scores de antes e de depois\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Validação final do modelo\n",
    "\n",
    "* Qual é a accuracy e o F-score do modelo otimizado utilizando os dados de testes?\n",
    "* Estes scores são melhores ou piores do que o modelo antes da otimização? \n",
    "* Como os resultados do modelo otimizado se comparam aos benchmarks do naive predictor que você encontrou na **Questão 1**?_\n",
    "\n",
    "**Nota:** Preencha a tabela abaixo com seus resultados e então responda as questões no campo **Resposta** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:\n",
    "\n",
    "|     Metric     | Unoptimized Model | Optimized Model |\n",
    "| :------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score |  0.8297           |    0.8415       |\n",
    "| F-score        |  0.6493           |   0.6861        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "O modelo otimizado apresentou uma precisão de 84,15%, que é 1,18% maior que os modelos não otimizados de 82,97%. O modelo otimizado entregou um escore F de 68,61%, que é 3,68% maior do que os modelos não otimizados de 64,93%. Ambas as pontuações são melhores do que os modelos não otimizados.\n",
    "\n",
    "Os resultados do meu modelo otimizado são muito superiores ao benchmark de previsão. Deve ser lembrado que esse preditor é ingênuo, pois sempre assumiu que um indivíduo ganhou mais de US $ 50.000. Nesse cenário, não haverá negativos verdadeiros ou falsos negativos. \n",
    "\n",
    "Enfim, o modelo otimizado está tendo um desempenho melhor do que o benchmark, o que indica que o modelo e seus parâmetros foram escolhidos corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Importância dos atributos\n",
    "\n",
    "Uma tarefa importante quando realizamos aprendizado supervisionado em um conjunto de dados como os dados do censo que estudamos aqui é determinar quais atributos fornecem maior poder de predição. Focando no relacionamento entre alguns poucos atributos mais importantes e na label alvo nós simplificamos muito o nosso entendimento do fenômeno, que é a coisa mais importante a se fazer. No caso deste projeto, isso significa que nós queremos identificar um pequeno número de atributos que possuem maior chance de predizer se um indivíduo possui renda anual superior à \\$50,000.\n",
    "\n",
    "Escolha um classificador da scikit-learn (e.x.: adaboost, random forests) que possua o atributo `feature_importance_`, que é uma função que calcula o ranking de importância dos atributos de acordo com o classificador escolhido. Na próxima célula python ajuste este classificador para o conjunto de treinamento e utilize este atributo para determinar os 5 atributos mais importantes do conjunto de dados do censo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 6 - Observação da Relevância dos Atributos\n",
    "Quando **Exploramos os dados**, vimos que existem treze atributos disponíveis para cada registro nos dados do censo. Destes treze atributos, quais os 5 atributos que você acredita que são os mais importantes para predição e em que ordem você os ranquearia? Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**\n",
    "education_level: O nível educa pode ser um preditor para o nível de trabalho qualificado ou não qualificado que alguém poderia obter. Por exemplo, alguém com um diploma universitário em ciência da computação poderia trabalhar para uma empresa de software, ganhando um grande salário, enquanto alguém que só obteve um diploma do ensino médio pode trabalhar em um papel menos especializado e qualificado, ganhando menos. No entanto, também pode haver exceções, onde uma pessoa sem diploma pode ser empreendedor e ganhar uma quantia relevante.\n",
    "\n",
    "Ocupação: Continuando com a educação, a ocupação real também será útil para determinar o salário - por exemplo, você se formou em uma faculdade de artes e passou a trabalhar em empregos de nível médio, ou se formou como médico, que trabalha como cirurgião-chefe em um hospital\n",
    "\n",
    "horas por semana: isto é, para aqueles empregados pelo estado ou em particular, matemática simples. Na maior parte, aqueles que trabalham 40 a 50 horas por semana devem receber mais do que os que trabalham, digamos, 10 horas por semana. No entanto, a ocupação é um fator importante nisso, pois você pode trabalhar 50 horas por semana no McDonalds ou 10 horas por semana como banqueiro de investimentos. É por isso que avaliei a ocupação como superior.\n",
    "\n",
    "ganho de capital: Quais são seus ganhos de capital monetário atuais (indicação da riqueza atual e ganhos anuais potenciais). Eu classifiquei isso acima da perda de capital simplesmente porque havia amostras de dados muito mais povoadas para ganho de capital e, portanto, mais úteis para modelagem.\n",
    "\n",
    "idade: Por fim, incluí a idade, pois sinto que a experiência e a oportunidade de subir a escada da progressão devem mostrar alguma correlação com a idade de uma pessoa. Por exemplo, alguém que está fora da Universidade há 5 anos, como se opor a alguém que está fora da Universidade há 20 anos, deve mostrar uma tendência de ganhos reais comparativamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Extraindo a importância do atributo\n",
    "Escolha um algoritmo de aprendizado supervisionado da `sciki-learn` que possui o atributo `feature_importance_` disponível. Este atributo é uma função que ranqueia a importância de cada atributo dos registros do conjunto de dados quando realizamos predições baseadas no algoritmo escolhido.\n",
    "\n",
    "Na célula de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar um modelo de aprendizado supervisionado da sklearn se este for diferente dos três usados anteriormente. \n",
    " - Treinar o modelo supervisionado com todo o conjunto de treinamento.\n",
    " - Extrair a importância dos atributos utilizando `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Importar um modelo de aprendizado supervisionado que tenha 'feature_importances_'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Treinar o modelo utilizando o conjunto de treinamento com .fit(X_train, y_train)\n",
    "model = RandomForestClassifier(random_state=7).fit(X_train, y_train)\n",
    "\n",
    "# TODO: Extrair a importância dos atributos utilizando .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Plotar\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 7 - Extraindo importância dos atributos\n",
    "\n",
    "Observe a visualização criada acima que exibe os cinco atributos mais relevantes para predizer se um indivíduo possui remuneração igual ou superior à \\$50,000 por ano.\n",
    "\n",
    "* Como estes cinco atributos se comparam com os 5 atributos que você discutiu na **Questão 6**? \n",
    "* Se você estivesse próximo da mesma resposta, como esta visualização confirma o seu raciocínio? \n",
    "* Se você não estava próximo, por que você acha que estes atributos são mais relevantes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**\n",
    "Das cinco características listadas acima (idade, horas por semana, ganho de capital, estado civil, relacionamento), três delas eram iguais às minhas (idade, hora por semana, ganho de capital). Isso se correlaciona com meu entendimento de que com a idade, a experiência e, provavelmente, um salário grande, que as horas por semana que você trabalha são importantes (pois a maioria contratou horas que refletem seu salário individual) e que o ganho de capital é um bom indicador riqueza percebida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando atributos\n",
    "\n",
    "Como um modelo performa se nós só utilizamos um subconjunto de todos os atributos disponíveis nos dados? Com menos atributos necessários para treinar, a expectativa é que o treinamento e a predição sejam executados em um tempo muito menor — com o custo da redução nas métricas de performance. A partir da visualização acima, nós vemos que os cinco atributos mais importantes contribuem para mais de 50% da importância de **todos** os atributos presentes nos dados. Isto indica que nós podemos tentar *reduzir os atributos* e simplificar a informação necessária para o modelo aprender. O código abaixo utilizará o mesmo modelo otimizado que você encontrou anteriormente e treinará o modelo com o mesmo conjunto de dados de treinamento, porém apenas com *os cinco atributos mais importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model trained on full data\n",
      "------\n",
      "Accuracy on testing data: 0.8415\n",
      "F-score on testing data: 0.6861\n",
      "\n",
      "Final Model trained on reduced data\n",
      "------\n",
      "Accuracy on testing data: 0.7823\n",
      "F-score on testing data: 0.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabi_\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importar a funcionalidade para clonar um modelo\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduzir a quantidade de atributos\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Treinar o melhor modelo encontrado com a busca grid anterior\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Fazer novas predições\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Reportar os scores do modelo final utilizando as duas versões dos dados.\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 8 - Efeitos da seleção de atributos\n",
    "\n",
    "* Como o F-score do modelo final e o accuracy score do conjunto de dados reduzido utilizando apenas cinco atributos se compara aos mesmos indicadores utilizando todos os atributos? \n",
    "* Se o tempo de treinamento é uma variável importante, você consideraria utilizar os dados enxutos como seu conjunto de treinamento? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**\n",
    "\n",
    "\n",
    "A queda de precisão usando o conjunto de recursos reduzido é boa, com uma queda de 6% na precisão quando comparado com o conjunto completo de 13 recursos. Eu ficaria feliz em usar essa pontuação de precisão reduzida se o tempo de treinamento fosse um fator, já que 78% ainda é um ótimo resultado para remover mais da metade dos recursos (5 Vs 13).\n",
    "\n",
    "No entanto, o F-score vê uma queda substancialmente maior, caindo pouco mais de 20%. Isso não é aceitável para mim, já que queremos um f-score o mais próximo possível de 1. Anteriormente, com os 13 recursos e otimização completos, estávamos alcançando cerca de 70% em nosso f-score. Com o conjunto de treinamento reduzido, não estamos nem recebendo 50%. Uma opção seria considerar outros modelos para ver se eles forneceriam uma pontuação melhor ajustada com o conjunto reduzido que eu listei anteriormente como muito lento (SVM) no conjunto completo de recursos. Se o SVC pudesse fornecer um f-score próximo ao valor de 68%, com tempo de treinamento reduzido, então eu consideraria usar o conjunto de treinamento reduzido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você tenha concluído toda a implementação de código e respondido cada uma das questões acima, você poderá finalizar o seu trabalho exportando o iPython Notebook como um documento HTML. Você pode fazer isso utilizando o menu acima navegando para \n",
    "**File -> Download as -> HTML (.html)**. Inclua este documento junto do seu notebook como sua submissão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
